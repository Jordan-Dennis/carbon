{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import ticktack\n",
    "import matplotlib.pyplot as pyplot\n",
    "# import jupyterthemes\n",
    "import functools\n",
    "\n",
    "# jupyterthemes.jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ticktack.load_presaved_model(\"Guttler15\", production_rate_units=\"atoms/cm^2/s\")\n",
    "model.compile()\n",
    "\n",
    "MATRIX = model._matrix\n",
    "PROJECTION = model._production_coefficients\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename: str, /, sep: str=\",\"):\n",
    "    \"\"\"\n",
    "    A custom `JAX` file loading protocol designed to be very quick and return a value that is `JAX` transformable. \n",
    "    \n",
    "    Parameters:\n",
    "        filename: String -> The file address of the data\n",
    "    Returns:\n",
    "        DeviceArray -> The data in column major order\n",
    "    \"\"\"\n",
    "    with open(filename) as data:    # Opening the data file\n",
    "        _ = next(data)              # Header row for the data \n",
    "\n",
    "        data = jax.numpy.array(\n",
    "            [row.strip().split(sep) for row in data], \n",
    "            dtype=jax.numpy.float64\n",
    "        )\n",
    "        \n",
    "        return data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_out = jax.numpy.linspace(0, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply = jax.jit(jax.vmap(jax.numpy.multiply, in_axes=(None, 0)))\n",
    "matrix_multiply = jax.jit(jax.vmap(jax.numpy.matmul, in_axes=(0, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals, eigenvecs = jax.numpy.linalg.eig(MATRIX)\n",
    "eigenvecs, eigenvals = eigenvecs.real, eigenvals.real\n",
    "inverse = jax.numpy.linalg.inv(eigenvecs)\n",
    "initial_position = 1.0 / jax.numpy.linalg.norm(PROJECTION) * PROJECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def fundamental_matrix(time_out, /, eigenvecs=eigenvecs, eigenvals=eigenvals, inverse=inverse):\n",
    "    \"\"\"\n",
    "    This constructs the right hand side of the fundamental solution matrix. It is vectorised and so returns a three dimensional array with the third dimension spanning the time series implied by `time_out`.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    : time_out :  The time series over which the fundamental matrix is to be calculated\n",
    "    : eigenvecs : The eigenvectors of the transfer matrix\n",
    "    : eigenvals : The eigenvalues of the transfer matrix\n",
    "    : inverse : The inverse of the eigenvectors of the transfer matrix. This could be calculated internally but since the evaluation is only required once it is passed as an argument.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    : DeviceArray : The fundamental solution matrix evaluated over the time series implied by `time_out`\n",
    "    \"\"\"\n",
    "    # So I need to implement the translation of the time series back onto 0\n",
    "    exponents = jax.numpy.exp(multiply(eigenvals, time_out))\n",
    "    transition_matrix = multiply(eigenvecs, exponents)\n",
    "    transition_matrix = matrix_multiply(transition_matrix, inverse)\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def analytic_template(time_out, /, initial_poisition=initial_position):\n",
    "    \"\"\"\n",
    "    Determines the analytic solution of an impulse response function over the time series provided by `time_out`.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    : time_out : The time series at which the analytic solution is to be evaluated\n",
    "    : inverse : The inverse of the eigenvectors of the transfer matrix\n",
    "    \n",
    "    \"\"\"\n",
    "    transition_matrix = fundamental_matrix(time_out - time_out.min())\n",
    "    return matrix_multiply(transition_matrix, initial_poisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "intcal = load(\"/home/jordan/Documents/ticktack/src/data/datasets/IntCal20/Intcal20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def design_matrix(time_series):\n",
    "    \"\"\"\n",
    "    Constructs the design matrix of the linear regression. \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    : time_series : The time over which to evaluate the design matrix.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    : DeviceArray : A 3 by n matrix where n is the length of `time_series`.\n",
    "    \"\"\"\n",
    "    constant = jax.numpy.ones((time_series.shape), dtype=jax.numpy.float64)\n",
    "    # So I think that the prescence of the zero values is going to cause problems\n",
    "    # I need to look into the `jax.lax.dynamic_slice_update()` to fix this.\n",
    "    temporal = (time_series - time_series.min()) / time_series.ptp()\n",
    "    analytic = analytic_template(time_series)[:, 1]\n",
    "    return jax.numpy.stack([constant, temporal, analytic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all utility functions for the bad boy \n",
    "# The in_window function is causing headaches because it cannot be passed the data\n",
    "@jax.jit\n",
    "def in_window(start, data, size):\n",
    "    @jax.vmap\n",
    "    def comp_util(start):\n",
    "        return (data[0] >= start) & (data[0] < start + size)\n",
    "    return comp_util(start)\n",
    "\n",
    "vec_mat = jax.jit(jax.vmap(design_matrix)) # Vectorising the deisgn matrix command\n",
    "vec_reg = jax.jit(jax.vmap(jax.numpy.linalg.lstsq)) # Vectorising the lstq function \n",
    "vec_matmul = jax.jit(jax.vmap(jax.numpy.matmul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def vec_regression(data, /, size: int=10):\n",
    "    start = data[0, :-size] # Storing as a variable for the usefulness \n",
    "    mask = in_window(start, data=data, size=size)      # Creates a boolean mask of out of date\n",
    "    lead_dim = data[0].size      # A useful size parameter for the mapping \n",
    "\n",
    "    indices = jax.numpy.arange(start.size) # Inex entry points to get a fill value\n",
    "    fill_values = jax.numpy.take(data, indices, axis=1) # Data sliced along dimension\n",
    "    fill_values = fill_values.repeat(lead_dim) # Element wise repetition\n",
    "    fill_values = fill_values.reshape(3, -1, lead_dim)\n",
    "\n",
    "    data = data.tile(start.size) # Replicating the data \n",
    "    data = data.reshape(3, -1, lead_dim) # Shaping for a push through where\n",
    "\n",
    "    # The error is here. Where is not pulling the correct data out\n",
    "    masked_data = jax.numpy.where(mask, data, fill_values)\n",
    "    masked_matrix = vec_mat(masked_data[0]) # Building the design matrixes\n",
    "\n",
    "    input_arr = jax.numpy.transpose(masked_matrix, axes=(0, 2, 1)) # Gettinf the sahpe compatible with the leading dimesnion of the data\n",
    "    lst_square = vec_reg(input_arr, masked_data[1])[0] # Performing regression \n",
    "    \n",
    "    models = vec_matmul(lst_square, masked_matrix) # Running the models\n",
    "    chi_squared = jax.numpy.sum((masked_data[1] - models) ** 2 / masked_data[2] ** 2, axis=1)\n",
    "    return jax.numpy.hstack([lst_square, chi_squared.reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_vec_reg =jax.vmap(vec_regression)\n",
    "\n",
    "# The idea is to run the injection recovery in batches. I don't remeber getting the nans as \n",
    "# outputs with the slower function. That said I don't remember looking too closely at the \n",
    "# output. I think they might be legit but I don't know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dim = intcal.shape[1] # Chosing the largest dimension to batch along\n",
    "num_batches = 8 # Number of batches (must be multiple)\n",
    "leading_dim = batched_dim // num_batches # Length of the new leading dim\n",
    "batched_data = intcal.reshape(3, leading_dim, num_batches) # Conforming array to batches\n",
    "batched_data = jax.numpy.transpose(batched_data, axes=(2, 0, 1)) # Placing the map axis in front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_vec_reg(batched_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_one = vec_regression(intcal[:, :1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = group_one[:, 2]\n",
    "nan_mask = jax.numpy.isnan(coefficients)\n",
    "indices = jax.numpy.arange(coefficients.size)\n",
    "nan_index = indices * nan_mask\n",
    "# coefficients = jax.numpy.delete(coefficients, nan_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,  44,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0, 398,   0, 400,   0, 402,   0, 404,   0, 406, 407,\n",
       "               0, 409,   0, 411,   0, 413, 414, 415,   0, 417, 418, 419,\n",
       "             420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
       "             432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443,\n",
       "             444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "             456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "             468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
       "             480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "             492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
       "             504, 505, 506, 507, 508, 509, 510, 511, 512, 513,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0, 536,   0,   0, 539,\n",
       "             540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
       "             552, 553, 554, 555, 556, 557,   0, 559,   0,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0, 570, 571, 572, 573, 574, 575,\n",
       "             576, 577, 578,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0, 589, 590, 591, 592, 593,   0,   0, 596, 597, 598, 599,\n",
       "             600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n",
       "             612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "               0, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635,\n",
       "             636,   0,   0,   0, 640,   0,   0, 643, 644, 645, 646, 647,\n",
       "             648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658,   0,\n",
       "             660,   0, 662, 663,   0,   0,   0, 667, 668, 669, 670, 671,\n",
       "             672,   0, 674,   0, 676, 677,   0, 679,   0,   0, 682, 683,\n",
       "             684, 685, 686,   0, 688, 689, 690, 691, 692, 693, 694, 695,\n",
       "             696, 697, 698, 699, 700, 701, 702, 703, 704,   0,   0,   0,\n",
       "               0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "               0,   0,   0, 723, 724, 725, 726, 727, 728, 729, 730, 731,\n",
       "             732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743,\n",
       "             744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755,\n",
       "             756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767,\n",
       "             768, 769, 770, 771, 772, 773, 774, 775, 776,   0,   0,   0,\n",
       "               0,   0,   0, 783, 784, 785, 786, 787, 788, 789, 790, 791,\n",
       "             792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803,\n",
       "             804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815,\n",
       "             816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827,\n",
       "             828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839,\n",
       "             840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851,\n",
       "             852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863,\n",
       "             864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875,\n",
       "             876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887,\n",
       "             888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899,\n",
       "             900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911,\n",
       "             912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923,\n",
       "             924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
       "             936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947,\n",
       "             948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959,\n",
       "             960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971,\n",
       "             972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983,\n",
       "             984, 985, 986, 987, 988, 989], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_vals = list(map(float, coefficients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x403.2 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(0)\n",
    "pyplot.hist(hist_vals, bins=30)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab79d763119790aea00e8eaeb5d3be48434571919ae202ec38e1b7aefb77c6d3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
